{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISE DA FREQUENCIA DOS ADJETIVOS\n",
    "\n",
    "A proposta aqui é representar o texto em função dos adjetivos encontrados. Ao invés de um bag-of-words ser um bag-of-adjectives. Primeiro testar com todos os adjetivos sem qualquer restrição. Após isso podemos pegar somente os adjetivos mais frequentes, adjetivos exclusivos de uma classe e assim em diante.\n",
    "Portanto para cada análise, os seguintes passos serão executados;\n",
    "<ol>\n",
    "    <li>Normalização do texto: remoção dos acentos, cedilhas, passar letras maiúsculas para minúsculas</li>\n",
    "    <li>Vetorização do texto</li>\n",
    "    <li>Remoção da média e setar desvio padrão unitário</li>\n",
    "    <li>Analise da correlação geral do conjunto de dados</li>\n",
    "    <li>Analise da correlação dentro de cada classe</li>\n",
    "    <li>Dividir o conjunto em treino e teste</li>\n",
    "    <li>Teste dos classificadores: MultinomialNB, SVM e KMeans</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pickle import load\n",
    "from nltk import FreqDist\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from database_utils import DatabaseConnector, build_dataframe, normalize_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de funções úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_from_db(sentiment = None):\n",
    "    db_connector = DatabaseConnector('localhost', 'root', '12345', 'CORPUS_VIES')\n",
    "    if sentiment != None:\n",
    "        retrieved_data = build_dataframe(db_connector.getDataBySentiment(sentiment))\n",
    "    else:\n",
    "        retrieved_data = build_dataframe(db_connector.getDataTextAndLabel())\n",
    "\n",
    "    return retrieved_data\n",
    "\n",
    "def load_tagger():\n",
    "    f = open('bigram_tagger.pkl', 'rb')\n",
    "    tagger = load(f)\n",
    "    f.close()\n",
    "    return tagger\n",
    "\n",
    "def get_all_adjectives():\n",
    "    corpus = get_data_from_db()\n",
    "    corpus = corpus['texts'].tolist()\n",
    "    tagger = load_tagger()\n",
    "        \n",
    "    adjectives = set()\n",
    "    for text in corpus:\n",
    "        adjectives_found = set([word for (word, tag) in tagger.tag(text.split()) if tag[:3] == 'ADJ'])\n",
    "        adjectives = adjectives.union(adjectives_found)\n",
    "        \n",
    "    print(\"Numero de adjetivos encontrados: \", len(adjectives))\n",
    "    return adjectives\n",
    "\n",
    "def get_adjective_by_sentiment(sentiment):\n",
    "    lista = get_data_from_db(sentiment= sentiment)\n",
    "\n",
    "    result_list = []\n",
    "    for sentence in lista:\n",
    "        result = tagger.tag(sentence[0].split())\n",
    "        result_list += result\n",
    "\n",
    "    fd = FreqDist([word for (word,tag) in result_list if tag[:3] == 'ADJ'])\n",
    "    adj_set = set(fd.keys())\n",
    "    print(len(adj_set), ' Adjectives encountered\\n')\n",
    "    \n",
    "    return adj_set\n",
    "\n",
    "def adjective_vectorizer(sentence, base_adjectives):\n",
    "#     normalized_sentence  = normalize_text(sentence)\n",
    "    normalized_sentence  = sentence\n",
    "    v = {adjective: normalized_sentence.split().count(adjective) for adjective in base_adjectives}\n",
    "    return v\n",
    "\n",
    "def get_correlation_matrix(matrix_data):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(\"Tamanho do corpus: \", matrix_data.shape[0])\n",
    "    print(\"Dimensionalidade: \", matrix_data.shape[1])\n",
    "    \n",
    "    corr_matrix = np.corrcoef(bag_of_words)\n",
    "    plt.figure()\n",
    "    plt.imshow(np.multiply(corr_matrix, 255), cmap='Greys_r')\n",
    "    plt.show()\n",
    "    \n",
    "    return corr_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT PARAGRAPH, POLARITY FROM PARAGRAPHS WHERE POLARITY IS NOT NULL AND trim(POLARITY) <> \"\"\n",
      "1042  Paragraphs encountered\n",
      "Numero de adjetivos encontrados:  473\n",
      "[('difícil', 'ADJ')]\n",
      "[('dificil', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "adj_list = get_all_adjectives()\n",
    "s = 'processamento de sinais é difícil'\n",
    "adjective_vectorizer(s, adj_list)\n",
    "\n",
    "tagger = load_tagger()\n",
    "print(tagger.tag([\"difícil\"]))\n",
    "print(tagger.tag([\"dificil\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e muito dificil caca'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import unicodedata\n",
    "s='é muito Difícil caça'\n",
    "s = s.lower()\n",
    "s = ''.join((c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn'))\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
