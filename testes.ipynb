{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT PARAGRAPH, POLARITY FROM PARAGRAPHS WHERE POLARITY IS NOT NULL AND trim(POLARITY) <> \"\"\n",
      "1042  Paragraphs encountered\n"
     ]
    }
   ],
   "source": [
    "from database_utils import DatabaseConnector, build_dataframe\n",
    "\n",
    "db_connector = DatabaseConnector('localhost', 'root', '12345', 'CORPUS_VIES')\n",
    "retrieved_data = build_dataframe(db_connector.getDataTextAndLabel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanceamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='6f00cb21-6c47-4154-ab8e-357faed8e92c'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x()+rect.get_width()/2., 1.0*height, '%d'%int(height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "positive_data = retrieved_data.loc[retrieved_data['labels'] == 'PO']\n",
    "negative_data = retrieved_data.loc[retrieved_data['labels'] == 'NG']\n",
    "neutral_data = retrieved_data.loc[retrieved_data['labels'] == 'NE']\n",
    "\n",
    "values = [positive_data.shape[0], negative_data.shape[0], neutral_data.shape[0]]\n",
    "\n",
    "xlabels = [\"Positivos\", \"Negativos\", \"Neutros\"]\n",
    "indexes = np.arange(len(xlabels))\n",
    "barWidth = 0.35\n",
    "\n",
    "f1 = plt.figure()\n",
    "ax1 = f1.add_subplot(111)\n",
    "\n",
    "p = ax1.bar(indexes, values, barWidth, tick_label = values)\n",
    "plt.ylabel('Quantidade')\n",
    "plt.xlabel('Classes')\n",
    "plt.title('Balanceamento do Dataset')\n",
    "plt.xticks(indexes + barWidth/2., xlabels)\n",
    "\n",
    "autolabel(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo\n",
      "Usando somente os unigramas\n",
      "Total news classified: 701\n",
      "Score: 0.587035827195\n",
      "Accuracy: 0.68480449946\n",
      "Confusion matrix:\n",
      "[[316  75]\n",
      " [146 164]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caiomagno/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:3117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "from database_utils import DatabaseConnector, build_dataframe\n",
    "from machine_learning_utils import MLWrapper\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "input_data = retrieved_data[(retrieved_data['labels'] == \"PO\") | (retrieved_data['labels'] == \"NG\")]\n",
    "input_data['labels'].replace(to_replace = \"NG\", value = 0, inplace = True)\n",
    "input_data['labels'].replace(to_replace = \"PO\", value = 1, inplace = True)\n",
    "\n",
    "print(\"Treinando o modelo\")\n",
    "print(\"Usando somente os unigramas\")\n",
    "pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "ml = MLWrapper(pipeline)\n",
    "pipeline = ml.train(input_data, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentando outro classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caiomagno/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:3443: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total news classified: 701\n",
      "Score: 0.585455197062\n",
      "Accuracy: 0.650518223794\n",
      "Confusion matrix:\n",
      "[[278 113]\n",
      " [132 178]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from machine_learning_utils import MLWrapper\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"Treinando o modelo\")\n",
    "input_data = retrieved_data[(retrieved_data['labels'] == \"PO\") | (retrieved_data['labels'] == \"NG\")]\n",
    "input_data['labels'].replace(to_replace = \"NG\", value = 0, inplace = True)\n",
    "input_data['labels'].replace(to_replace = \"PO\", value = 1, inplace = True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('classifier', SVC(C= 316))\n",
    "    ])\n",
    "\n",
    "ml = MLWrapper(pipeline)\n",
    "ml.train(input_data, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Stemming\n",
    "\n",
    "Utilizar o stemming para o portugues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Exemplo\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "stemmer.stem(\"COPIAR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodando os mesmo algoritmos com o Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from database_utils import DatabaseConnector, build_dataframe\n",
    "from machine_learning_utils import MLWrapper\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print(\"Treinando o modelo\")\n",
    "ml_wrapper = MLWrapper(MultinomialNB())\n",
    "ml_wrapper.train(retrieved_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "f = open('bigram_tagger.pkl', 'rb')\n",
    "tagger = load(f)\n",
    "f.close()\n",
    "\n",
    "tagger.tag(['Aécio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Frequencia dos Adjetivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from nltk import FreqDist\n",
    "\n",
    "def get_adjective_by_sentiment(sentiment):\n",
    "    db = pymysql.connect('localhost', 'root', '12345', 'CORPUS_VIES')\n",
    "    cursor = db.cursor()\n",
    "\n",
    "    sql_statement = 'SELECT PARAGRAPH FROM PARAGRAPHS WHERE POLARITY = \"%s\"' %sentiment\n",
    "    print(sql_statement)\n",
    "\n",
    "    cursor.execute(sql_statement)\n",
    "    print(cursor.rowcount, ' Paragraphs encountered')\n",
    "    lista = cursor.fetchall()\n",
    "    db.close()\n",
    "\n",
    "    result_list = []\n",
    "    for sentence in lista:\n",
    "        result = tagger.tag(sentence[0].split())\n",
    "        result_list += result\n",
    "\n",
    "    fd = FreqDist([word for (word,tag) in result_list if tag[:3] == 'ADJ'])\n",
    "    adj_set = set(fd.keys())\n",
    "    print(len(adj_set), ' Adjectives encountered\\n')\n",
    "    \n",
    "    return adj_set\n",
    "\n",
    "pos_adj = get_adjective_by_sentiment(\"PO\")\n",
    "neg_adj = get_adjective_by_sentiment(\"NG\")\n",
    "neu_adj = get_adjective_by_sentiment(\"NE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_excl = pos_adj.difference(neg_adj.union(neu_adj))\n",
    "neg_excl = neg_adj.difference(pos_adj.union(neu_adj))\n",
    "neu_excl = neu_adj.difference(neg_adj.union(pos_adj))\n",
    "\n",
    "print('Quantidade de adjetivos exclusivos')\n",
    "print('Positivos: ', len(pos_excl))\n",
    "print('Negativos: ', len(neg_excl))\n",
    "print('Neutros: ', len(neu_excl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from pandas import DataFrame\n",
    "\n",
    "# retrieved_data[retrieved_data['labels'] == 'NE']\n",
    "\n",
    "# for l in retrieved_data.values:\n",
    "#     print(l)\n",
    "\n",
    "def adj_incidence(textdata_df):\n",
    "    f = open('bigram_tagger.pkl', 'rb')\n",
    "    tagger = load(f)\n",
    "    f.close()\n",
    "    \n",
    "    adj_class_counter = {'pos':0, 'neg':0, 'neu':0}\n",
    "    for value in textdata_df.values:\n",
    "        tokens = value[1].split()\n",
    "        tags = tagger.tag(tokens)\n",
    "        adjs = [token for token, tag in tags if tag == \"ADJ\" ]\n",
    "        for adj in adjs:\n",
    "            if adj in neg_excl: adj_class_counter['neg']+=1\n",
    "            if adj in pos_excl: adj_class_counter['pos']+=1\n",
    "            if adj in neu_excl: adj_class_counter['neu']+=1\n",
    "    return adj_class_counter\n",
    "        \n",
    "pos_data = retrieved_data[retrieved_data['labels'] == 'PO']\n",
    "neg_data = retrieved_data[retrieved_data['labels'] == 'NG']\n",
    "neu_data = retrieved_data[retrieved_data['labels'] == 'NE']\n",
    "\n",
    "count_pos = adj_incidence(pos_data)\n",
    "count_neg = adj_incidence(neg_data)\n",
    "count_neu = adj_incidence(neu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_pos, count_neg, count_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(adj_incidence(pos_data.iloc[1]))\n",
    "print(pos_data.iloc[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pos_excl)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}