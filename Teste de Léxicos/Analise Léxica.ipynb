{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import re\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "all_data = get_data_from_db()\n",
    "all_data = all_data[(all_data[\"labels\"]== \"PO\") | (all_data[\"labels\"]== \"NG\")]\n",
    "\n",
    "num_remover = NumRemover()\n",
    "word_remover = WordRemover(stopwords.words('portuguese'))\n",
    "all_data = num_remover.fit_transform(all_data)\n",
    "all_data = word_remover.fit_transform(all_data)\n",
    "\n",
    "neg_data = all_data[all_data[\"labels\"] == \"NG\"]\n",
    "pos_data = all_data[all_data[\"labels\"] == \"PO\"]\n",
    "\n",
    "ratio = 0.7\n",
    "neg_train = neg_data.iloc[0:round(ratio*neg_data.shape[0]), :]\n",
    "pos_train = pos_data.iloc[0:round(ratio*pos_data.shape[0]), :]\n",
    "\n",
    "neg_test = neg_data.iloc[round(ratio*neg_data.shape[0]): , :]\n",
    "pos_test = pos_data.iloc[round(ratio*neg_data.shape[0]): , :]\n",
    "\n",
    "stopwords_pt = stopwords.words(\"portuguese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão vocabulario negativo: 2687\n",
      "Dimensão vocabulario positivo: 2326\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vocab_neg = set(' '.join(neg_train[\"texts\"].tolist()).split())\n",
    "vocab_pos = set(' '.join(pos_train[\"texts\"].tolist()).split())\n",
    "\n",
    "print(\"Dimensão vocabulario negativo: \" + str(len(vocab_neg)))\n",
    "print(\"Dimensão vocabulario positivo: \" + str(len(vocab_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verificar interseção dos vocabulários\n",
    "intersect = vocab_neg.intersection(vocab_pos)\n",
    "vocab_neg = vocab_neg.difference(intersect)\n",
    "vocab_pos = vocab_pos.difference(intersect)\n",
    "\n",
    "lexicon = list(vocab_neg.union(vocab_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Cross Validation:\n",
      "Fold  0  - Acuracia:  0.822695035461\n",
      "Fold  1  - Acuracia:  0.778571428571\n",
      "Fold  2  - Acuracia:  0.807142857143\n",
      "Fold  3  - Acuracia:  0.785714285714\n",
      "Fold  4  - Acuracia:  0.807142857143\n",
      "\n",
      "Accuracia media:  0.800253292806\n",
      "Desvio padrão:  0.0160003123144\n",
      "\n",
      "\n",
      "SVM\n",
      "Cross Validation:\n",
      "Fold  0  - Acuracia:  0.723404255319\n",
      "Fold  1  - Acuracia:  0.742857142857\n",
      "Fold  2  - Acuracia:  0.785714285714\n",
      "Fold  3  - Acuracia:  0.742857142857\n",
      "Fold  4  - Acuracia:  0.707142857143\n",
      "\n",
      "Accuracia media:  0.740395136778\n",
      "Desvio padrão:  0.0263072323206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes  import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "features = FeatureUnion([\n",
    "                    (\"bigram\", CountVectorizer(ngram_range=(2,2), stop_words= stopwords_pt, binary= True)),\n",
    "                    (\"lexicon_vector\", CountVectorizer(vocabulary= lexicon))\n",
    "                    ])\n",
    "\n",
    "print(\"MultinomialNB\")\n",
    "run_cross_validation(all_data, features, MultinomialNB(), n_folds=5)\n",
    "\n",
    "print(\"\\n\\nSVM\")\n",
    "run_cross_validation(all_data, features, SVC(C=316), n_folds=5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
