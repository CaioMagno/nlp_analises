{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalidade\n",
      "CLAUDIA: Unigram, 2 labels:  513\n",
      "LIWC:Unigram, 2 labels:  27187\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import re\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "numRemover = NumRemover()\n",
    "\n",
    "all_data3 = get_data_from_db()\n",
    "all_data3 = numRemover.fit_transform(all_data3)\n",
    "all_data2 = all_data3[(all_data3[\"labels\"]== \"PO\") | (all_data3[\"labels\"]== \"NG\")]\n",
    "\n",
    "lexicon_claudia = load_claudia_freitas_lexicon()\n",
    "lexicon_liwc = get_LIWC_lexicon()\n",
    "\n",
    "unigramVectorizer_claudia = CountVectorizer(ngram_range=(1,1), stop_words= stopwords.words('portuguese'), vocabulary= lexicon_claudia)\n",
    "unigramVectorizer_liwc = CountVectorizer(ngram_range=(1,1), stop_words= stopwords.words('portuguese'), vocabulary= lexicon_liwc)\n",
    "unigramVectorizer_claudia_binary = CountVectorizer(ngram_range=(1,1), binary = True, stop_words= stopwords.words('portuguese'), vocabulary= lexicon_claudia)\n",
    "unigramVectorizer_liwc_binary = CountVectorizer(ngram_range=(1,1), binary = True, stop_words= stopwords.words('portuguese'), vocabulary= lexicon_liwc)\n",
    "\n",
    "print(\"Dimensionalidade\")\n",
    "print(\"CLAUDIA: Unigram, 2 labels: \", unigramVectorizer_claudia.fit_transform(all_data2['texts']).shape[1])\n",
    "print(\"LIWC:Unigram, 2 labels: \", unigramVectorizer_liwc.fit_transform(all_data2['texts']).shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************\n",
      "***********CLAUDIA FREITAS******************\n",
      "********************************************\n",
      "-------------FEATURE FREQUENCY--------------\n",
      "Unigrams, Positive and Negative Texts\n",
      "********************************************\n",
      "Naive Bayes---------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.537806841046\n",
      "Desvio padrão:  0.0191858149292\n",
      "\n",
      "MaxEnt--------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.547826961771\n",
      "Desvio padrão:  0.0306739172322\n",
      "\n",
      "SVM-----------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.539235412475\n",
      "Desvio padrão:  0.0200222944534\n",
      "********************************************\n",
      "********************************************\n",
      "Unigrams, Positive, Negative and Neutral Texts\n",
      "********************************************\n",
      "Naive Bayes---------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.387772133527\n",
      "Desvio padrão:  0.0240007714495\n",
      "\n",
      "MaxEnt--------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.354208998549\n",
      "Desvio padrão:  0.0304225539039\n",
      "\n",
      "SVM-----------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.388715529753\n",
      "Desvio padrão:  0.0180387469277\n",
      "********************************************\n",
      "-------------FEATURE PRESENCE---------------\n",
      "Unigrams, Positive and Negative Texts\n",
      "********************************************\n",
      "Naive Bayes---------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.549215291751\n",
      "Desvio padrão:  0.0231332685112\n",
      "\n",
      "MaxEnt--------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.547766599598\n",
      "Desvio padrão:  0.0346654096566\n",
      "\n",
      "SVM-----------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.536378269618\n",
      "Desvio padrão:  0.0212994380384\n",
      "********************************************\n",
      "********************************************\n",
      "Unigrams, Positive, Negative and Neutral Texts\n",
      "********************************************\n",
      "Naive Bayes---------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.388733671988\n",
      "Desvio padrão:  0.024047606224\n",
      "\n",
      "MaxEnt--------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.351324383164\n",
      "Desvio padrão:  0.033479208016\n",
      "\n",
      "SVM-----------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.385830914369\n",
      "Desvio padrão:  0.0231276214304\n",
      "********************************************\n"
     ]
    }
   ],
   "source": [
    "# Learning algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"********************************************\")\n",
    "print(\"***********CLAUDIA FREITAS******************\")\n",
    "print(\"********************************************\")\n",
    "print(\"-------------FEATURE FREQUENCY--------------\")\n",
    "print(\"Unigrams, Positive and Negative Texts\")\n",
    "print(\"********************************************\")\n",
    "evaluate(all_data2, unigramVectorizer_claudia, 10)\n",
    "print(\"********************************************\")\n",
    "print(\"********************************************\")\n",
    "print(\"Unigrams, Positive, Negative and Neutral Texts\")\n",
    "print(\"********************************************\")\n",
    "evaluate(all_data3, unigramVectorizer_claudia, 10)\n",
    "print(\"********************************************\")\n",
    "\n",
    "print(\"-------------FEATURE PRESENCE---------------\")\n",
    "print(\"Unigrams, Positive and Negative Texts\")\n",
    "print(\"********************************************\")\n",
    "evaluate(all_data2, unigramVectorizer_claudia_binary, 10)\n",
    "print(\"********************************************\")\n",
    "print(\"********************************************\")\n",
    "print(\"Unigrams, Positive, Negative and Neutral Texts\")\n",
    "print(\"********************************************\")\n",
    "evaluate(all_data3, unigramVectorizer_claudia_binary, 10)\n",
    "print(\"********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************\n",
      "******************LIWC**********************\n",
      "********************************************\n",
      "-------------FEATURE FREQUENCY--------------\n",
      "Unigrams, Positive and Negative Texts\n",
      "********************************************\n",
      "Naive Bayes---------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.661911468813\n",
      "Desvio padrão:  0.0469476520978\n",
      "\n",
      "MaxEnt--------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.644788732394\n",
      "Desvio padrão:  0.0430806463645\n",
      "\n",
      "SVM-----------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.557766599598\n",
      "Desvio padrão:  0.00187122736419\n",
      "********************************************\n",
      "********************************************\n",
      "Unigrams, Positive, Negative and Neutral Texts\n",
      "********************************************\n",
      "Naive Bayes---------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.479934687954\n",
      "Desvio padrão:  0.0409779400075\n",
      "\n",
      "MaxEnt--------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.466509433962\n",
      "Desvio padrão:  0.0511207624877\n",
      "\n",
      "SVM-----------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.376197387518\n",
      "Desvio padrão:  0.00289276218113\n",
      "********************************************\n",
      "-------------FEATURE PRESENCE---------------\n",
      "Unigrams, Positive and Negative Texts\n",
      "********************************************\n",
      "Naive Bayes---------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.671891348089\n",
      "Desvio padrão:  0.0424010121044\n",
      "\n",
      "MaxEnt--------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.63629778672\n",
      "Desvio padrão:  0.0567470207526\n",
      "\n",
      "SVM-----------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.557766599598\n",
      "Desvio padrão:  0.00187122736419\n",
      "********************************************\n",
      "********************************************\n",
      "Unigrams, Positive, Negative and Neutral Texts\n",
      "********************************************\n",
      "Naive Bayes---------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.478955007257\n",
      "Desvio padrão:  0.0411051964642\n",
      "\n",
      "MaxEnt--------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.456839622642\n",
      "Desvio padrão:  0.0475132253186\n",
      "\n",
      "SVM-----------------------------------------\n",
      "Cross Validation:\n",
      "Accuracia media:  0.375235849057\n",
      "Desvio padrão:  0.000707547169811\n",
      "********************************************\n"
     ]
    }
   ],
   "source": [
    "# Learning algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"********************************************\")\n",
    "print(\"******************LIWC**********************\")\n",
    "print(\"********************************************\")\n",
    "print(\"-------------FEATURE FREQUENCY--------------\")\n",
    "print(\"Unigrams, Positive and Negative Texts\")\n",
    "print(\"********************************************\")\n",
    "evaluate(all_data2, unigramVectorizer_liwc, 10)\n",
    "print(\"********************************************\")\n",
    "print(\"********************************************\")\n",
    "print(\"Unigrams, Positive, Negative and Neutral Texts\")\n",
    "print(\"********************************************\")\n",
    "evaluate(all_data3, unigramVectorizer_liwc, 10)\n",
    "print(\"********************************************\")\n",
    "\n",
    "print(\"-------------FEATURE PRESENCE---------------\")\n",
    "print(\"Unigrams, Positive and Negative Texts\")\n",
    "print(\"********************************************\")\n",
    "evaluate(all_data2, unigramVectorizer_liwc_binary, 10)\n",
    "print(\"********************************************\")\n",
    "print(\"********************************************\")\n",
    "print(\"Unigrams, Positive, Negative and Neutral Texts\")\n",
    "print(\"********************************************\")\n",
    "evaluate(all_data3, unigramVectorizer_liwc_binary, 10)\n",
    "print(\"********************************************\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
